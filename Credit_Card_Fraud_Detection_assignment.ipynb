{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit Card Fraud Detection assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVZQlE_lc2db"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z4Zj0VZc2dh"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfYna9wc2di"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2d9OfUYc2dj"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEUKMN4c2dj"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKgDG1Ugc2dk"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RroopI-Vc2dl"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FU1svZZc2dl"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kekrS2zhc2dm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZsS8WH1dKxF",
        "outputId": "ec4846c4-d666-45d4-fe8c-5b945c9009ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGbTbgQldBl7"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "R5JYTqH-c2dm",
        "outputId": "b6878916-7847-4dcc-bc09-0fb779880225"
      },
      "source": [
        "card_df = pd.read_csv('/content/drive/MyDrive/DL_Assignments_PIAIC/DataSets/creditcard.csv')\n",
        "card_df.head(10)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686133</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "5   2.0 -0.425966  0.960523  1.141109  ...  0.253844  0.081080    3.67      0\n",
              "6   4.0  1.229658  0.141004  0.045371  ...  0.034507  0.005168    4.99      0\n",
              "7   7.0 -0.644269  1.417964  1.074380  ... -1.206921 -1.085339   40.80      0\n",
              "8   7.0 -0.894286  0.286157 -0.113192  ...  0.011747  0.142404   93.20      0\n",
              "9   9.0 -0.338262  1.119593  1.044367  ...  0.246219  0.083076    3.68      0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn3e3rsneO9n"
      },
      "source": [
        "# Checking Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTokQ2gheN-_",
        "outputId": "fd798cde-6e62-4fbf-80df-0b19e83a10c0"
      },
      "source": [
        "card_df.isnull().any()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      False\n",
              "V1        False\n",
              "V2        False\n",
              "V3        False\n",
              "V4        False\n",
              "V5        False\n",
              "V6        False\n",
              "V7        False\n",
              "V8        False\n",
              "V9        False\n",
              "V10       False\n",
              "V11       False\n",
              "V12       False\n",
              "V13       False\n",
              "V14       False\n",
              "V15       False\n",
              "V16       False\n",
              "V17       False\n",
              "V18       False\n",
              "V19       False\n",
              "V20       False\n",
              "V21       False\n",
              "V22       False\n",
              "V23       False\n",
              "V24       False\n",
              "V25       False\n",
              "V26       False\n",
              "V27       False\n",
              "V28       False\n",
              "Amount    False\n",
              "Class     False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpTtfnwthLbA",
        "outputId": "d67868be-e231-4783-e348-c56d6f4e4fa1"
      },
      "source": [
        "card_df.shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqQXGpkrhwNA",
        "outputId": "d1fcd854-b9f2-45ac-d2c8-e184a12e2872"
      },
      "source": [
        "zero_val = np.where(card_df.Amount.apply(lambda x: x==0))\n",
        "np.array(zero_val).size"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsBvrx7Y6RCV"
      },
      "source": [
        "card_df.reset_index(drop=True, inplace=True)\n",
        "labels = card_df.pop('Class')"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "1dfBIB2d9Mxf",
        "outputId": "ca278eed-f6cf-49ed-af79-e81fe4e108f7"
      },
      "source": [
        "card_df.head()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V26       V27       V28  Amount\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ... -0.189115  0.133558 -0.021053  149.62\n",
              "1   0.0  1.191857  0.266151  0.166480  ...  0.125895 -0.008983  0.014724    2.69\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.139097 -0.055353 -0.059752  378.66\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ... -0.221929  0.062723  0.061458  123.50\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.502292  0.219422  0.215153   69.99\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "-Sl392VOc2dn",
        "outputId": "c0d395ce-06f7-4ef1-81d4-0f73bcb517ce"
      },
      "source": [
        "card_df.describe()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...           V28         Amount\n",
              "count  284807.000000  2.848070e+05  ...  2.848070e+05  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ... -1.206049e-16      88.349619\n",
              "std     47488.145955  1.958696e+00  ...  3.300833e-01     250.120109\n",
              "min         0.000000 -5.640751e+01  ... -1.543008e+01       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ... -5.295979e-02       5.600000\n",
              "50%     84692.000000  1.810880e-02  ...  1.124383e-02      22.000000\n",
              "75%    139320.500000  1.315642e+00  ...  7.827995e-02      77.165000\n",
              "max    172792.000000  2.454930e+00  ...  3.384781e+01   25691.160000\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU_WySBsj_iL"
      },
      "source": [
        "# Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg8bmoJrlPoT"
      },
      "source": [
        "mean = card_df.mean(axis=0)\n",
        "card_df -= mean\n",
        "card_df /= card_df.std(axis=0)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTvHmqXrl7p8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "446e6f69-8649-491b-f652-999a52f63987"
      },
      "source": [
        "card_df.head()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.996580</td>\n",
              "      <td>-0.694241</td>\n",
              "      <td>-0.044075</td>\n",
              "      <td>1.672771</td>\n",
              "      <td>0.973364</td>\n",
              "      <td>-0.245116</td>\n",
              "      <td>0.347067</td>\n",
              "      <td>0.193679</td>\n",
              "      <td>0.082637</td>\n",
              "      <td>0.331127</td>\n",
              "      <td>0.083385</td>\n",
              "      <td>-0.540406</td>\n",
              "      <td>-0.618295</td>\n",
              "      <td>-0.996097</td>\n",
              "      <td>-0.324610</td>\n",
              "      <td>1.604011</td>\n",
              "      <td>-0.536832</td>\n",
              "      <td>0.244863</td>\n",
              "      <td>0.030770</td>\n",
              "      <td>0.496281</td>\n",
              "      <td>0.326117</td>\n",
              "      <td>-0.024923</td>\n",
              "      <td>0.382854</td>\n",
              "      <td>-0.176911</td>\n",
              "      <td>0.110507</td>\n",
              "      <td>0.246585</td>\n",
              "      <td>-0.392170</td>\n",
              "      <td>0.330891</td>\n",
              "      <td>-0.063781</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.996580</td>\n",
              "      <td>0.608495</td>\n",
              "      <td>0.161176</td>\n",
              "      <td>0.109797</td>\n",
              "      <td>0.316522</td>\n",
              "      <td>0.043483</td>\n",
              "      <td>-0.061820</td>\n",
              "      <td>-0.063700</td>\n",
              "      <td>0.071253</td>\n",
              "      <td>-0.232494</td>\n",
              "      <td>-0.153349</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.066087</td>\n",
              "      <td>0.491417</td>\n",
              "      <td>-0.149982</td>\n",
              "      <td>0.694359</td>\n",
              "      <td>0.529433</td>\n",
              "      <td>-0.135170</td>\n",
              "      <td>-0.218762</td>\n",
              "      <td>-0.179086</td>\n",
              "      <td>-0.089611</td>\n",
              "      <td>-0.307376</td>\n",
              "      <td>-0.880075</td>\n",
              "      <td>0.162201</td>\n",
              "      <td>-0.561130</td>\n",
              "      <td>0.320693</td>\n",
              "      <td>0.261069</td>\n",
              "      <td>-0.022256</td>\n",
              "      <td>0.044607</td>\n",
              "      <td>-0.342474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.996558</td>\n",
              "      <td>-0.693499</td>\n",
              "      <td>-0.811576</td>\n",
              "      <td>1.169466</td>\n",
              "      <td>0.268231</td>\n",
              "      <td>-0.364571</td>\n",
              "      <td>1.351451</td>\n",
              "      <td>0.639775</td>\n",
              "      <td>0.207372</td>\n",
              "      <td>-1.378673</td>\n",
              "      <td>0.190699</td>\n",
              "      <td>0.611829</td>\n",
              "      <td>0.066137</td>\n",
              "      <td>0.720699</td>\n",
              "      <td>-0.173114</td>\n",
              "      <td>2.562902</td>\n",
              "      <td>-3.298230</td>\n",
              "      <td>1.306866</td>\n",
              "      <td>-0.144790</td>\n",
              "      <td>-2.778556</td>\n",
              "      <td>0.680974</td>\n",
              "      <td>0.337631</td>\n",
              "      <td>1.063356</td>\n",
              "      <td>1.456317</td>\n",
              "      <td>-1.138090</td>\n",
              "      <td>-0.628536</td>\n",
              "      <td>-0.288446</td>\n",
              "      <td>-0.137137</td>\n",
              "      <td>-0.181021</td>\n",
              "      <td>1.160684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.996558</td>\n",
              "      <td>-0.493324</td>\n",
              "      <td>-0.112169</td>\n",
              "      <td>1.182514</td>\n",
              "      <td>-0.609726</td>\n",
              "      <td>-0.007469</td>\n",
              "      <td>0.936148</td>\n",
              "      <td>0.192070</td>\n",
              "      <td>0.316017</td>\n",
              "      <td>-1.262501</td>\n",
              "      <td>-0.050468</td>\n",
              "      <td>-0.221891</td>\n",
              "      <td>0.178371</td>\n",
              "      <td>0.510168</td>\n",
              "      <td>-0.300360</td>\n",
              "      <td>-0.689836</td>\n",
              "      <td>-1.209294</td>\n",
              "      <td>-0.805443</td>\n",
              "      <td>2.345300</td>\n",
              "      <td>-1.514202</td>\n",
              "      <td>-0.269855</td>\n",
              "      <td>-0.147443</td>\n",
              "      <td>0.007267</td>\n",
              "      <td>-0.304776</td>\n",
              "      <td>-1.941024</td>\n",
              "      <td>1.241902</td>\n",
              "      <td>-0.460217</td>\n",
              "      <td>0.155396</td>\n",
              "      <td>0.186188</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.996537</td>\n",
              "      <td>-0.591329</td>\n",
              "      <td>0.531540</td>\n",
              "      <td>1.021410</td>\n",
              "      <td>0.284655</td>\n",
              "      <td>-0.295015</td>\n",
              "      <td>0.071998</td>\n",
              "      <td>0.479301</td>\n",
              "      <td>-0.226510</td>\n",
              "      <td>0.744325</td>\n",
              "      <td>0.691624</td>\n",
              "      <td>-0.806145</td>\n",
              "      <td>0.538626</td>\n",
              "      <td>1.352242</td>\n",
              "      <td>-1.168031</td>\n",
              "      <td>0.191323</td>\n",
              "      <td>-0.515204</td>\n",
              "      <td>-0.279080</td>\n",
              "      <td>-0.045569</td>\n",
              "      <td>0.987036</td>\n",
              "      <td>0.529938</td>\n",
              "      <td>-0.012839</td>\n",
              "      <td>1.100009</td>\n",
              "      <td>-0.220123</td>\n",
              "      <td>0.233250</td>\n",
              "      <td>-0.395201</td>\n",
              "      <td>1.041609</td>\n",
              "      <td>0.543619</td>\n",
              "      <td>0.651815</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2  ...       V27       V28    Amount\n",
              "0 -1.996580 -0.694241 -0.044075  ...  0.330891 -0.063781  0.244964\n",
              "1 -1.996580  0.608495  0.161176  ... -0.022256  0.044607 -0.342474\n",
              "2 -1.996558 -0.693499 -0.811576  ... -0.137137 -0.181021  1.160684\n",
              "3 -1.996558 -0.493324 -0.112169  ...  0.155396  0.186188  0.140534\n",
              "4 -1.996537 -0.591329  0.531540  ...  0.543619  0.651815 -0.073403\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nwUSZ3m-LhK"
      },
      "source": [
        "# Spliting into Training and Testing labels Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASuWy3F8nuLm"
      },
      "source": [
        "dfCard_len = len(card_df)\n",
        "train_data = card_df.iloc[:dfCard_len*50//100]\n",
        "val_data = card_df.iloc[dfCard_len*50//100:dfCard_len*70//100]\n",
        "test_data = card_df.iloc[dfCard_len*70//100:]\n",
        "labels_len = len(labels)\n",
        "train_labels = labels.iloc[:labels_len*50//100]\n",
        "val_labels = labels.iloc[labels_len*50//100:labels_len*70//100]\n",
        "test_labels = labels.iloc[labels_len*70//100:]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvAFwsgN_Xg4"
      },
      "source": [
        "# Building Model with activation = 'tanh'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N87Fopxmc2do",
        "outputId": "feb59aa0-eae2-49f7-8d3e-f740b96b67da"
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10,activation=\"tanh\",input_shape=(len(train_data.columns),) ))\n",
        "network.add(layers.Dense(8,activation=\"tanh\" ))\n",
        "network.add(layers.Dense(6,activation=\"tanh\"))\n",
        "network.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "network.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "with tf.device('/device:GPU:1'):\n",
        "  MODEL = network.fit(train_data,train_labels,epochs=100,batch_size=256,validation_data=(val_data,val_labels))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "557/557 [==============================] - 3s 4ms/step - loss: 0.2412 - acc: 0.9224 - val_loss: 1.2371 - val_acc: 0.5807\n",
            "Epoch 2/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 1.3721 - val_acc: 0.6171\n",
            "Epoch 3/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 1.2761 - val_acc: 0.6458\n",
            "Epoch 4/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 1.3031 - val_acc: 0.6490\n",
            "Epoch 5/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 1.1688 - val_acc: 0.6741\n",
            "Epoch 6/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.1333 - val_acc: 0.6893\n",
            "Epoch 7/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.0078 - val_acc: 0.7156\n",
            "Epoch 8/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.9434 - val_acc: 0.7330\n",
            "Epoch 9/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.8115 - val_acc: 0.7594\n",
            "Epoch 10/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.7063 - val_acc: 0.7895\n",
            "Epoch 11/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.6178 - val_acc: 0.8116\n",
            "Epoch 12/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.5864 - val_acc: 0.8195\n",
            "Epoch 13/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.4968 - val_acc: 0.8413\n",
            "Epoch 14/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 0.9995 - val_loss: 0.4137 - val_acc: 0.8673\n",
            "Epoch 15/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.3434 - val_acc: 0.8878\n",
            "Epoch 16/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.2832 - val_acc: 0.9123\n",
            "Epoch 17/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.2609 - val_acc: 0.9206\n",
            "Epoch 18/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.2867 - val_acc: 0.9099\n",
            "Epoch 19/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.2842 - val_acc: 0.9099\n",
            "Epoch 20/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.2918 - val_acc: 0.9059\n",
            "Epoch 21/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.2254 - val_acc: 0.9274\n",
            "Epoch 22/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.2572 - val_acc: 0.9160\n",
            "Epoch 23/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.1741 - val_acc: 0.9401\n",
            "Epoch 24/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.2097 - val_acc: 0.9295\n",
            "Epoch 25/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1550 - val_acc: 0.9463\n",
            "Epoch 26/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1882 - val_acc: 0.9318\n",
            "Epoch 27/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1748 - val_acc: 0.9368\n",
            "Epoch 28/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1281 - val_acc: 0.9557\n",
            "Epoch 29/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1525 - val_acc: 0.9460\n",
            "Epoch 30/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1701 - val_acc: 0.9397\n",
            "Epoch 31/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1591 - val_acc: 0.9424\n",
            "Epoch 32/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1537 - val_acc: 0.9442\n",
            "Epoch 33/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1134 - val_acc: 0.9570\n",
            "Epoch 34/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1083 - val_acc: 0.9589\n",
            "Epoch 35/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.1176 - val_acc: 0.9571\n",
            "Epoch 36/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.1246 - val_acc: 0.9538\n",
            "Epoch 37/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1405 - val_acc: 0.9503\n",
            "Epoch 38/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1160 - val_acc: 0.9578\n",
            "Epoch 39/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1193 - val_acc: 0.9569\n",
            "Epoch 40/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1171 - val_acc: 0.9576\n",
            "Epoch 41/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1075 - val_acc: 0.9610\n",
            "Epoch 42/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1050 - val_acc: 0.9623\n",
            "Epoch 43/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1079 - val_acc: 0.9619\n",
            "Epoch 44/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0797 - val_acc: 0.9728\n",
            "Epoch 45/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1118 - val_acc: 0.9597\n",
            "Epoch 46/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0979 - val_acc: 0.9652\n",
            "Epoch 47/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0934 - val_acc: 0.9672\n",
            "Epoch 48/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0781 - val_acc: 0.9733\n",
            "Epoch 49/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0950 - val_acc: 0.9674\n",
            "Epoch 50/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1049 - val_acc: 0.9620\n",
            "Epoch 51/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1115 - val_acc: 0.9598\n",
            "Epoch 52/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1054 - val_acc: 0.9619\n",
            "Epoch 53/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1196 - val_acc: 0.9568\n",
            "Epoch 54/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.1560 - val_acc: 0.9417\n",
            "Epoch 55/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1131 - val_acc: 0.9594\n",
            "Epoch 56/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.2213 - val_acc: 0.9169\n",
            "Epoch 57/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1770 - val_acc: 0.9354\n",
            "Epoch 58/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1152 - val_acc: 0.9583\n",
            "Epoch 59/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.1501 - val_acc: 0.9457\n",
            "Epoch 60/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.1121 - val_acc: 0.9612\n",
            "Epoch 61/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.1219 - val_acc: 0.9581\n",
            "Epoch 62/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1236 - val_acc: 0.9580\n",
            "Epoch 63/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1422 - val_acc: 0.9486\n",
            "Epoch 64/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1245 - val_acc: 0.9574\n",
            "Epoch 65/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1554 - val_acc: 0.9458\n",
            "Epoch 66/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1574 - val_acc: 0.9464\n",
            "Epoch 67/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1223 - val_acc: 0.9571\n",
            "Epoch 68/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1780 - val_acc: 0.9359\n",
            "Epoch 69/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1479 - val_acc: 0.9462\n",
            "Epoch 70/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1440 - val_acc: 0.9489\n",
            "Epoch 71/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1754 - val_acc: 0.9410\n",
            "Epoch 72/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1040 - val_acc: 0.9639\n",
            "Epoch 73/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.1513 - val_acc: 0.9472\n",
            "Epoch 74/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1469 - val_acc: 0.9485\n",
            "Epoch 75/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0927 - val_acc: 0.9682\n",
            "Epoch 76/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0983 - val_acc: 0.9655\n",
            "Epoch 77/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1387 - val_acc: 0.9472\n",
            "Epoch 78/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1470 - val_acc: 0.9460\n",
            "Epoch 79/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1313 - val_acc: 0.9508\n",
            "Epoch 80/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1747 - val_acc: 0.9342\n",
            "Epoch 81/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1900 - val_acc: 0.9296\n",
            "Epoch 82/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.1558 - val_acc: 0.9394\n",
            "Epoch 83/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1353 - val_acc: 0.9468\n",
            "Epoch 84/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1328 - val_acc: 0.9481\n",
            "Epoch 85/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0787 - val_acc: 0.9678\n",
            "Epoch 86/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1011 - val_acc: 0.9601\n",
            "Epoch 87/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1455 - val_acc: 0.9430\n",
            "Epoch 88/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1709 - val_acc: 0.9352\n",
            "Epoch 89/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1742 - val_acc: 0.9333\n",
            "Epoch 90/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0850 - val_acc: 0.9666\n",
            "Epoch 91/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1529 - val_acc: 0.9409\n",
            "Epoch 92/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0925 - val_acc: 0.9628\n",
            "Epoch 93/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0960 - val_acc: 0.9622\n",
            "Epoch 94/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0848 - val_acc: 0.9673\n",
            "Epoch 95/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0929 - val_acc: 0.9643\n",
            "Epoch 96/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1763 - val_acc: 0.9325\n",
            "Epoch 97/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1072 - val_acc: 0.9580\n",
            "Epoch 98/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0952 - val_acc: 0.9633\n",
            "Epoch 99/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1021 - val_acc: 0.9618\n",
            "Epoch 100/100\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0670 - val_acc: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGYzSjwDIQO"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8aa-Bn3oUiZ",
        "outputId": "72bd4dee-b429-4513-e348-821298fe0e46"
      },
      "source": [
        "test_loss , test_acc = network.evaluate(test_data,test_labels)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2671/2671 [==============================] - 4s 2ms/step - loss: 0.3650 - acc: 0.8586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-6PZ9Lc2do",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "15abc688-fb7a-4515-e464-37d7dd4f33a6"
      },
      "source": [
        "history_dict = MODEL.history\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epoches = np.arange(1,len(history_dict['acc'])+1)\n",
        "plt.plot(epoches,acc_values,'-',label=\"Training Accuracy\")\n",
        "plt.plot(epoches,val_acc_values,'r',label=\"Validation Accuracy\")\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hU5fXA8e/ZpVepioCCSFGCS1mRgFItCAgKQcGKBYWYKJho1CRKLImJ/GKLDRtiEKwQQATpohRZepEOSm/S++6c3x/vnd3ZYXZ3dtnZ2Z05n+fZZ+b2c++dvee+73uLqCrGGGPiV0K0AzDGGBNdlgiMMSbOWSIwxpg4Z4nAGGPinCUCY4yJc5YIjDEmzlkiMJmIyNcicld+jxtNIrJZRK6OwHxVRC72vr8lIn8NZ9w8LOc2Efkmr3EakxOx+wiKPhE5EtBZBjgJpHndD6jqyIKPqvAQkc3Afao6NZ/nq0B9VV2fX+OKSB1gE1BcVVPzI86ciEhdYAPwtqoOLIhlmsLFSgQxQFXL+f+An4EbAvqlJwERKRa9KE0hdiewH7hFREoW5IJFJLEgl2dCs0QQw0SkvYhsFZE/ichO4AMRqSQiE0Rkj4js977XCphmpojc533vJyLfichQb9xNInJ9HsetKyLfishhEZkqIq+LyH+ziDucGJ8Vke+9+X0jIlUDht8hIj+JyD4R+XM22+cKEdkZeDASkZtEZJn3vaWIzBWRAyKyQ0T+IyIlspjXcBF5LqD7UW+a7SJyT9C4XUVksYgcEpEtIjIkYPC33ucBETkiIr/2b9uA6VuLyAIROeh9tg5324SIW3CJ4C/AaeCGoOE9RGSJF+sGEens9a8sIh9467dfRMZ6/TPF6vULrEIbLiJvishEETkKdMhheyAiV4rIHG8/bPGWcbmI7Aradz1FZGlW62qyZokg9p0HVAYuBO7H7fMPvO4LgOPAf7KZ/gpgDVAV+BfwnnfwyO24HwM/AFWAIcAd2SwznBhvBe4GqgMlgD8CiMilwJve/M/3lleLEFR1PnAU6Bg034+972nAYG99fg10An6bTdx4MXT24rkGqA8Et08cxR18zwG6AgNF5EZvWFvv8xyvRDc3aN6Vga+AV711+zfwlYhUCVqHM7ZNFq7EbZ/RwKdAepuPiLQERgCPerG2BTZ7gz/CVUM29pbzUjbLCHYr8DxQHviObLaHiFwIfA28BlQDmgJLVHUBsA+4NmC+d3jxmtxSVfuLoT/cP+rV3vf2wCmgVDbjNwX2B3TPxNWnA/QD1gcMKwMocF5uxsUdzFOBMgHD/wv8N8x1ChXjXwK6fwtM8r4/BYwOGFbW2wZXZzHv54D3ve/lcQelC7MYdxAwJqBbgYu978OB57zv7wMvBIzXIHDcEPN9GXjJ+17HG7dYwPB+wHfe9zuAH4Kmnwv0y2nbZLHsd4Gx3vdf40oF1b3ut/1xBU1TA/ABlUIMS481m+00Iof9Hbg9ngjc5kHj/QkY6X2vDBwDahTk/1us/FmJIPbtUdUT/g4RKSMib3tVJ4dwVRHnSNZ1tTv9X1T1mPe1XC7HPR/4JaAfwJasAg4zxp0B348FxHR+4LxV9SjuzDErHwM9xdWN9wQWqepPXhwNvGqpnV4cf8eVDnKSKQbgp6D1u0JEZnhVXweBAWHO1z/vn4L6/QTUDOjOattkIiKlgd7ASAB1pY+fcWfsALVxjcjBauP25/4wYw6Wad/nsD2yigHcycQNIlIWuBmYrao78hhTXLNEEPuCLwv7A9AQuEJVK5BRFZFVdU9+2AFUFpEyAf1qZzP+2cS4I3De3jKrZDWyqq7CHUivJ3O1ELgqptW4q30qAE/mJQZciSjQx8A4oLaqVgTeCphvTpfxbcdVmQW6ANgWRlzBbgIqAG94yW4nLqH4q4e2APVCTLcFtz/PCTHsKK40CICInBdinOB1zG57ZBUDqroNVxrqiSspfRRqPJMzSwTxpzyuzv2AV9/8dKQX6J1hpwBDRKSEiPyaoEbJfIzxc6Cb18BYAniGnH/nHwMP4xLOZ0FxHAKOiEgjINxLKz8F+onIpV4iCo6/PO6M+oRXD39rwLA9uGqXi7KY90SggYjcKiLFROQW4FJgQpixBboLV43VBFf91hRoAySJSBPgPeBuEekkIgkiUlNEGnln3V/jEkglESkuIv5kvRRoLCJNRaQUrj0oJ9ltj5HA1SJys7e+VUSkacDwEcBj3jp8mYdtYLBEEI9eBkoDe4F5wKQCWu5tuDrofbh6+U9w9zuEkucYVXUl8CDu4L4Dd1nk1hwmGwW0A6ar6t6A/n/EHZQOA+94MYcTw9feOkwH1nufgX4LPCMih3FtGp8GTHsM15D6vXeVTKugee8DuuFKTftwB8FuQXHnSERq4hq/X1bVnQF/C3Hb+y5V/QHX6PwScBCYRUZp5A5ce8JqYDeu/QRVXYtLvlOBdbjG4Jxktz1+Brp46/sLsARICph2jBfTmKCqR5MLdkOZiQoR+QRYraoRL5GY2CYiG3A3TubrDYPxxEoEpkB4133X86oYOgM9gLHRjssUbSLSC9fmEFzqMrlgd5qagnIerg63Cq6qZqCqLo5uSKYoE5GZuPaRO1TVF+VwijSrGjLGmDhnVUPGGBPnilzVUNWqVbVOnTrRDsMYY4qUhQsX7lXVaqGGFblEUKdOHVJSUqIdhjHGFCkiEnxHejqrGjLGmDhnicAYY+KcJQJjjIlzlgiMMSbOWSIwxpg4F7FEICLvi8huEVmRxXARkVdFZL2ILBOR5pGKxRhjTNYiWSIYDnTOZvj1uNf41ce9QvHNCMZijDEmCxG7j0BVvxWROtmM0gP3yjoF5onIOSJSoyDeMHQyNY3Za/dyKs2HTxVVsvxMUyXVp6Sl+RAREgREBMX/mk83TxH3Jg0F0nxKmi/rR3ekz9/rlvTpJb1/8HwD3xIs3js7NOD9HqqkT+cLemyICCSIkCiCounjhowpYFr/64ZVFf/qpMfqDfPHJQHva3HLc/0UN60vYFtlJ8HbxgnejH0Byw5ep8zrHhA3csbw4GmDt2mm4UHT+2MI3KdZvrXZkyiSvg6pPiXN58OnkJgg6evo3+ciGcvIbjuFWidV9X6XQmKCP97MvwP/7zTUbAVISBAvroD5krFdA5eVEcuZG+CMfeItV8Rbhvd/41/HrB5vk9VvS7N5Z0/w8kTcdlUFny9jSv//r/9/VL0JBPeby/o3kbGObttmbN/A/Rn4fxi47fzTBv+2Aued07+HAO0bVqdJrYo5jJl70byhrCaZX1m31et3RiIQkftxpQYuuCD4ZU+5N3LezzwzYdVZz8cYYwpSpbIlYi4RhE1VhwHDAJKTk8/6KXmTV+6kfvVy/OfW5ulnhwkJ4p0lujMX8TJ8sYQEEr0zJvDO3HyafsYRmM1VST+bTUjIOvND5rOPjLMI9c4uJODsIvNZRfDKB87Tf+bv/54+jXf2kuaPm4yzk0AJCRlnLIHLTkyQM9YzOK5A/uX5gtYnVOkhuFQDmWNNCHEWlXl7aMjh/v6B2yY4Pg3afhnrp5m6E4J+E+GUbPxn+KpK8cSE9G2YporPR0DJz30mBmwnf7z+ElXwOvv5x/d580xTzbRv/fEKbju6+WZeY/+29scbWFIK3K6B88woNZy57/yCx/cvJ/C3kCDBWz/n31ZWAucXOI+Ms3VJ39Y+VRLF/U+HKvWeGZO3D8j8Px74/5u+/dJLmwH/Z/5lhyyJZ8zbP112MYTaZvkhmolgG5nf61qLvL13NVf2Hz1Fyk/7GdiuHg3PKx/pxRmTSWE780pEKJ4Y7SgKStYHUXcCmPvp3LSQkOM4WVU7hXtgj0wC8Ivm5aPjgDu9q4daAQcLon1g5trdpPmUqy89N9KLMsaYIiFiJygiMgpoD1QVka24F3gXB1DVt3Av4e6Ce6frMdy7USNuyqpdVC9fkstq5n89mzHGFEWRvGqobw7DFfeS8QJzMjWNWWv20L1pTRISIlvUMsaYoiKu7iyet/EXjp5K45pLq0c7FGOMKTTiKhFMXbWL0sUTaV2varRDMcaYQiNuEoGqMvXHXbRtUJVS8XOZhDHG5ChuEsHK7YfYcfAEV19iVwsZY0yguEkEU1btIkGgYyNrHzDGmEBxkwj6t72I/957BVXKlYx2KKaoOnUqvNuKjYmE0aPhyJGIzDpuEkG5ksVofbE1EhvPunVw443w00/hjT9/PtSs6aY5diyysRkT7PvvoW9feOONiMw+bhKBMelUYeBA+N//YMiQnMefPh06dYJixWD8eLjmGvjll4iHaQzgfq+PPgo1asCDkbn1yhKBiT+ffw7TpkH9+vDRR7BhQ+jxVOHLL6FLF6hbFxYtgk8/hZQUuOoq2LIl9HQmZ3/7G/zrX7BvX8EuNy0NRo6EQ4cKZnlHjsDq1Wc3j7FjYe5ct83Kls2fuIKp9wz6ovLXokULNSbPDh9WrVVLtWlT1S1bVEuVUr377szjTJum+tvfql5wgXvMfcuWqvv2ZQyfPl21QgXVGjVU588v2Phjwdq1qv5XCJQqpXrPPao//1wwy/7kE7fca69VPX0699Pfd5/qP/8Z3rjLl6vWr++W17Gj6uTJqj5f7pZ36pRqgwaqjRrlLd4AQIpmcVyN+oE9t3+WCMxZefxx97P/7jvXPWiQamKi6vr1qqmprhtUy5RR7dFD9Z13VI8cOXM+y5er1qnjDmSjRhXsOhRmx4+rPvGE6q5dWY/z/PNuG0+apPrAA24bdu5cMPH17q1asqRb/oABuTswnzqlWqKEar16oYft3Ol+Q6qqo0e739C556r++c+q55/vltm+fcY4oZw8qTphgurKlappaapvvumm+9//creeIVgiMPFl3z7VDz9UHTzYnYlddJFqUpJqu3aqxYur3nlnxrjbt7sDUZ8+qt26uX+Jhx9WPXYs5+Xs3q161VVumjvvVJ0yxZ21paaqzpql+tBDqn/9q+qJExFbVZ09W3XHjsjNP7e++MJtjz/9KetxmjVTbdUqo/uJJ1QTEtyBNJKOHnUH5wEDXHyg+tJL4U+/ZElGSSa4BNOnj+svolqtmvvepo3qtm1u+MmTGSchK1aEnv/u3apt22Yso3Jl1fLlVa+8MvcliRAsEZjC6fhx1ZkzVTdsyJ/5HT6s+txzqhUranq1w+WXu3/S7t3dP1mHDmcecPylgMRE1ddfz90yT550B/yyZd08qldXPe88991/5tmypauGCmXbNtVhw/K2vv4DU8mSripr06a8zSc/3Xefi+ncc91ZcrD1693w//u/jH4rVrh+r7wS2dg++8wtZ9o0d7bds6c7cM+eHd7077+fcZD+8MOM/sePuwTTqZNL/Pffr/rss2eu/6pVbtoPPjhz3osXu6rIUqVU337bjXPvve63s3BhXtc4E0sEpvDw+VxVyg03uH8e/z9WgwbugLx4cfbT//vfqtdd5w58//63+6f5y19U+/VzB2FwB/0ffgi/TnXnThfPpEl5X6+jR92B5uabXfXDqFGqhw65M+Ry5Vxss2adOV3//qHPMAOtX+/aNebMydz/vvtUS5d2dezFi7tEdv75bty6dd22CfbVV6pTp2a/Lj/9lLdt4fOp1qyZkQjHjDlznH/8ww376afM/Zs2dQe9SLrlFtWqVTN+F0eOuLPum28Ob/rf/c4l/MqV3e/N7+uv3TpNnJj99Kmp7rfw4IOZ+69Y4f4XatVSTUkJf31yyRKByV9z5qj27esOfrk1bZr72V14oTuYjx2r+vLL7uDuP4O+8UZ3thvsjTfc8Hr1Ms76wVUr1Kyp2qXLmQfLwmDVKpfoKlRwycHv2LGM9ZgyJevp//lPN05gFcG+fS4J9O/vurdscXXR997rGr+Tk1WLFVNdtChjPnPmuH4VKmRdh5+amjHtL7/kbj2XL3dxvvWWS0hdupw5TosWoQ/4L77opl27NnfLDNexY+4gfv/9mfs/9JCr9w+8GCArrVu7fXDTTe736/fgg+5Afvx4zvNo1071iisy93v6afcbzqrUmE8sEZj81bOn++kMGpS76Xw+949Us2bof5r9+1WHDMk4OPburbpmjRs2frz7Z+nWzZ3R+Xyqe/e6M8tQVRCFzfz5bp1efTWjn/8KFlD9z3+ynrZ9e3dgBnf2qao6dKjrDpUwVd2BrUYN1Usvddv6l19c1UPNmq7kMGBA6On8yRZUR47M3Tr+619uOn9SSkjIXNLZsMENf/HFM6fdutVV0zz9dO6WGa4vvwydcBcvdv1fey376VNT3cH+4YfdPgTVjRvd7/CCC9yFBeH4wx/cCc/Jkxn9rrrKJd8Is0Rg8s/Bg+6HXLGi+8f99tvwp/3mG/eTy6ke/pdfXF1r2bLuoHXHHe6fsEWL0FfwFBWtWrnLCdPSXHfXrq46oHx5V+0QysGDLgk88oi7SqlFC3dQuugidwDJzqRJbnsPHuzOYosVcwnpd79zB+ngRsudO91+7djR1fGHW2Xi16GDapMm7vvGjW7Zf/tbxnB/ySartowOHVQvvjh0w+jixapz5+YunkB9+6pWqRK6urBZM9XmzbOffuVKTW8b8Jd83ntPddky9/2dd8KLY/RoN76/pHb0qKvWe/TR3K1PHlgiMPlnxAj3s/nmG3cwqlcvvIOzz+cOhLVrh38Vza5druhevLgrihemq2Py4uOP3babMMEddBMT3ZUkLVqoXnNN6Gn8Z7IzZ6oOH+6+33uv+/zkk5yX+dvfZpzhDx3q+u3dq3rOOWdesnnnnW5br17t2h/Kl8985uqXlub2/1NPZez7Q4fctI89ljHe1Ve7s+UTJ1zJpUkT13iflXffdXEG3puRmqr697+7bVWhQt5OBA4edHXz990Xerj/DD+79qmPPnLjLF/ufsvVqqnefruLDTKuDsqJv7Hcf4HAlCmaqaQXQZYITPi2b1ddty7r4ddf7w7KPp87OIE7WOfE36D21lu5j2nbNtU9e3I/XWFz6pSrO7/2WnfZIrgzzdtucwfMUPr3dwfAU6fcQbFRIzddjRrhVYkdPeoune3VK6Mkouqu2gF3JcyUKa6dBlSffNINHz/edU+enDHNyZPuyp4GDTKSi3++Y8a47hkzMsb3n/0WL54xfnZnzvv3u/r6Fi1cFeGnn7rSCWRcVjl8eM7rrOqqDO++W/VXv3JJBLJuJN+71y03u9/x4MHuih5/iaJ3b1fN9utfu3jD5fOpVqqU0bbzxBOupHb4cPjzyCNLBCZ8bdu6aoFQdfh79rgfbeA14g895H5Gb7yR9Tx37HB1oBdeGPoMM54895zbXrVqZdQLP/OM6xfc+O7zufF69szo9+mnbtwhQ8JfZmrqmdUtJ0640pz/AA0uyfhjOHbMNUb/9rcZ0/z+9268Vq3cGbL/CqC//c01wpYrl3n/njzp+j/yiGtv8Lf3ZOfll131kIim39j33nsu/gYN3LX5Odm3T7VhQ1e12KWLu6osu8Z4VVcNVqVK1qXV4EbewLaU3OwLVVf6a9bMfW/VyiWTAmCJwIRn9ersz9zeflvPKEIfP+4uvQyselB19c9//KOrDvDPc8SIyK9DYbd7d8bVUf6GY3+jcXDVRKj6Z5/PVReFc8NbTtavd8ueNcvt++CDYI8eLhH5fK66RiTzpY8+n6tOApcEbrzx7GPyO3JEdcEC14js52+MXrUq6+mOH3cXJJQoEfpy3az4S6yhrvFPS3OlsoEDM/r9+GPG7zq3l3w++aQ7odq925VW/KWwCLNEYM60cOGZZ2iPPeZ+mA0bql5ySeaqBFXXmNew4Zlnl6dOuWu0wZ0B+ovxxYu7ov0//pH5MsZ4d8897kC1e7fr9t8YNnp05vH8jasRvqwwS/4bqObPd9VLNWu6+vZAx4+7M2UIfd9Cftq1K6PhPJS0NHdmH2pb5iQ11a1H2bKqS5dmHrZunZvnu+9m9PP53P0SNWqc+X+SE3+7z1NPabZVVvnMEoHJzF/lcOGFGY1vp065m5569HDFeH+jpt+2bdlf3pea6m6yAdeI/K9/xUa9fiQcOuQaHf2OHnXbNvAKG1V32aj/Kpxo2LXLxXXRRW6/fvll6PG2b3dVhPv3Rz6mXr2yrsLxP8Mo1OWp4di+3SW7Cy/MfJ9F8JU+fiNG5P4SW1V3SS249ShRIn9Kd2GwRGAy818KB66xSjWjsW/cOJcUatVyByJVd5D3X32SXbE8Lc1VCeX2DMm4g8+tt2Z0+y8bze6ZPQWhTRtNv8mvMPBfEht8xdTy5a4EevPNZ/dcngULXKPwlVdmtHc89pibd361b/l8rh3O3wheQLJLBPY+gnj0zTfu89prYehQ+PFHeO899+KL66+H4sVh0CCYORO+/hquu869GemBB+CSS7Keb0ICNG7sPk3uNGwIa9ZkdE+eDKmpbn9E0+23Q5Uq8Npr0Y3D75pr4MIL4dVX4cQJ1y81Ffr1g3POgf/8B0TyPv/kZBg+HL77DmrVcus/YQI0aQIlSuTHGrj4kpPd944d82eeZyurDFFY/6xEkA+6dHFXYOze7S5la9HC3WDkLx2oujPSChXcWUupUq6+2ETOQw+5Blf/2exNN7k66OweWVxQzvI5+Pnurbfc77JxY9e+4r+W/7PP8m8Z48e7+wT8TxINfj7Q2RoyxM03Nw3aZwmrGjLpTpxwl+T5f9j+K4HgzPsH/vlPlySWLSv4OOPN66+7fbB1a8b19Ll9hEc8+fprlyhLlHDVNr17R2Y5aWmu2im/r/PftMldVVeAj0fJLhGIG150JCcna0pKSrTDKDomTYJf/coVc8FV93To4N7X2707+Hyuu2xZmDgxqqHGtWnT4Oqr3efmzXDvvfDDD3D55dGOrPDau9dVVy5c6LZV9erRjqhQE5GFqpocalixgg7GFKA9e6BrV2jTBmbNcnWTU6ZAYiK0b+/GSUhwB5+zqVc1Z69hQ/e5Zg188QVcfHFGPbIJrWpVt61U7fd7lqxVL5ZNnOjO+GfPdv8w4BqKW7WCChUyxitWzCUHEz01a7pS2YwZMH063HqrHdzCZdvprFkiKGr27Al/3PHj4fzz4bLL4NFHYds2V4y+9trIxWfyRsSVCj7/3J3h9u0b7YhMHLFEUJS88oqrB/3885zHPXnSXYJ4ww3w0kuu3rl3b3eQueaaiIdq8qBhQ7d/mjeHRo2iHY2JI5YIiorZs+EPf3B1+g89BIcOZT/+zJlw5IhLBB07Qo8eMHcuVKxoDZCFlb+d4LbbohuHiTuWCIqC7dvd2Xy9eu4qoJ07YciQ7KcZPx7KlMm4YeXFF92NYp06uTYBU/i0b+/aCqxayBQwOyIUdqdOuSRw5Ii7uqdxY7j/fndn5V13QVLSmdOowrhxrgqodGnXr359N33t2gUbvwlfu3awdWu0ozBxyEoEhd2oUTBnDrzzjksCAH//O1SuDAMGwIoV7m/tWpcAAJYtgy1b3H0Cga66CurUKdDwjTGFnyWCwu6bb+Dcc6FPn4x+lSu7qp5589wzUJo0cfXLbdvC8uWuNCDi7iEwxpgcWNVQYebzwdSproon+FrpO++Eiy6CXbtc97Zt8Oyz0KyZaxBu2dIlEGOMyUFEE4GIdAZeARKBd1X1haDhFwLvA9WAX4DbVdUqSf1WrIDdu92jB4KJuKqeQLffDk8+CcOGwc03F0yMxpgiL2JVQyKSCLwOXA9cCvQVkUuDRhsKjFDVy4BngH9EKp4iaepU9xkqEYRSpQq8/ba7ymjQoMjFZYyJKZFsI2gJrFfVjap6ChgN9Aga51Jguvd9Rojh8W3KFHdjkf+BceGqUcPeCWCMCVskjxY1gS0B3Vu9foGWAj297zcB5UWkSvCMROR+EUkRkZQ9uXnEQlF28iR8+234pQFjjMmjaJ82/hFoJyKLgXbANiAteCRVHaaqyaqaXK1atYKOMTrmzYNjxywRGGMiLpKNxduAwLuXann90qnqdrwSgYiUA3qp6oEIxlR0BD8u2hhjIiSSJYIFQH0RqSsiJYA+wLjAEUSkqoj4Y3gCdwWRAddQ3LKluxTUGGMiKGKJQFVTgd8Bk4EfgU9VdaWIPCMi/lte2wNrRGQtcC7wfKTiKVIOHIAFC6xayBhTICJ6H4GqTgQmBvV7KuD750AYz1SOMzNmuJvJ7HHRxpgCEO3GYhPK+PGuSuiKK6IdiTEmDlgiKGxSU92zgrp1gxIloh2NMSYOWCIobGbPhn374Kaboh2JMSZOWCIobMaMgVKloHPnaEdijIkTlggKE1UYOxauuw7Klo12NMaYOGGJoDBZuNC9UMaqhYwxBcgSQWHy5ZfubuIbboh2JMaYOGKJoDAZM8Y9UqJy5WhHYoyJI5YICovVq92fVQsZYwqYJYLC4n//c5833hjdOIwxcccSQWExfTr86ldQM/iVDcYYE1mWCAqD06fhu+/skdPGmKiwRFAYpKS4l9BYIjDGRIElgsJg5kz32a5dVMMwxsQnSwSFwYwZ0KQJVK0a7UiMMXHIEkG0nToF339v1ULGmKixRBBt1j5gjIkySwTR5m8faNs2qmEYY+KXJYJomznT2geMMVFliSCarH3AGFMIWCKIpgULrH3AGBN1lgiiacYM92ntA8aYKLJEEE2TJkGzZtY+YIyJKksE0bJ3L8yday+hMcZEnSWCaPn6a/D5oFu3aEdijIlzlgiiZcIEOO88aNEi2pEYY+JcjolARG4QEUsY+en0adc+0LUrJNimNcZEVzhHoVuAdSLyLxFpFOmA4sLs2XDokLUPGGMKhRwTgareDjQDNgDDRWSuiNwvIuUjHl2smjABSpaEq6+OdiTGGBNeG4GqHgI+B0YDNYCbgEUi8vsIxha7JkyAjh2hbNloR2KMMWG1EXQXkTHATKA40FJVrweSgD9ENrwYtGYNrFtnVwsZYwqNYmGM0wt4SVW/DeypqsdE5N7IhBXDxo93n5YIjDGFRDiJYAiww98hIqWBc1V1s6pOi1RgMWndOvj736FVK7jggmhHY4wxQHhtBJ8BvoDuNK+fyY2DB6F7d3e56MiR0Y7GGGPShVMiKKaqp/wdqnpKREpEMKbYk5YGffvC+vUwZQpcdFG0IzLGmHThlAj2iEh3f4eI9AD2Ri6kGHymNecAABwUSURBVPTss+6REq+9Zo+cNsYUOuGUCAYAI0XkP4AAW4A7IxpVLPH5YNgw1zg8YEC0ozHGmDPkmAhUdQPQSkTKed1HIh5VLFm8GHbsgN/8JtqRGGNMSOGUCBCRrkBjoJSIAKCqz4QxXWfgFSAReFdVXwgafgHwIXCON87jqjoxNytQ6H31FYjA9ddHOxJjjAkpnBvK3sI9b+j3uKqh3sCFYUyXCLwOXA9cCvQVkUuDRvsL8KmqNgP6AG/kKvqi4Kuv4PLLoXr1aEdijDEhhdNY3FpV7wT2q+rfgF8DDcKYriWwXlU3elcdjQZ6BI2jQAXve0Vge3hhFxG7dsEPP9jNY8aYQi2cRHDC+zwmIucDp3HPG8pJTVzDst9Wr1+gIcDtIrIVmIgrdZzBe8hdioik7NmzJ4xFFxJff+0+u3aNbhzGGJONcBLBeBE5B3gRWARsBj7Op+X3BYarai2gC/BRqHcfqOowVU1W1eRq1arl06ILwIQJcP757r3ExhhTSGXbWOwdlKep6gHgCxGZAJRS1YNhzHsbUDugu5bXL9C9QGcAVZ0rIqWAqsDuMOMvvE6dgm++gVtucY3FxhhTSGVbIlBVH67B1999MswkALAAqC8idb07kfsA44LG+RnoBCAilwClgCJU95ON776Dw4etWsgYU+iFUzU0TUR6ieTutFZVU4HfAZOBH3FXB60UkWcC7lT+A9BfRJYCo4B+qqq5WU6hNWEClChhL58xxhR6ktNxV0QOA2WBVFzDsQCqqhWynTBCkpOTNSUlJRqLzp0mTdzL6adMiXYkxhiDiCxU1eRQw8K5s9heSZlbhw7BypV2N7ExpkjIMRGISNtQ/YNfVGMCLFgAqu69A8YYU8iF84iJRwO+l8LdKLYQ6BiRiGLB/Pnus2XL6MZhjDFhCKdq6IbAbhGpDbwcsYhiwbx50LAhVKoU7UiMMSZH4Vw1FGwrcEl+BxIzVF2J4Ioroh2JMcaEJZw2gtdwzwQClzia4u4wNqFs3gy7d1v7gDGmyAinjSDwWs1UYJSqfh+heIo+f/uAJQJjTBERTiL4HDihqmngHi8tImVU9VhkQyui5s2D0qXdfQTGGFMEhHVnMVA6oLs0MDUy4cSA+fMhORmKhfXOH2OMibpwEkGpwNdTet/LRC6kIuzkSVi0yBqKjTFFSjiJ4KiINPd3iEgL4HjkQirCli51Tx219gFjTBESTv3FIOAzEdmOe87QebhXV5pg8+a5T0sExpgiJJwbyhaISCOgoddrjaqejmxYRdT8+VCzpvszxpgiIpyX1z8IlFXVFaq6AignIr+NfGhF0Ny51j5gjClywmkj6O+9oQwAVd0P9I9cSEXUli2waRO0DfmMPmOMKbTCSQSJgS+lEZFEoETkQiqiZs1yn+3aRTcOY4zJpXAaiycBn4jI2173A8DXkQupiJo1C845x24kM8YUOeEkgj8B9wMDvO5luCuHTKBZs+CqqyAxMdqRGGNMruRYNeS9wH4+sBn3LoKOuHcQG7/t22HdOqsWMsYUSVmWCESkAdDX+9sLfAKgqh0KJrQixNoHjDFFWHZVQ6uB2UA3VV0PICKDCySqombWLKhQAZo2jXYkxhiTa9lVDfUEdgAzROQdEemEu7PYBJs1C6680h40Z4wpkrJMBKo6VlX7AI2AGbhHTVQXkTdF5NqCCrDQ27ULVq+2aiFjTJEVTmPxUVX92Ht3cS1gMe5KIgPw7bfu0xKBMaaIytU7i1V1v6oOU9VOkQqoyJk1C8qWhebNcx7XGGMKoby8vN4EmjkT2rSB4sWjHYkxxuSJJYKz8eOPsHIldO4c7UiMMSbPLBGcjQ8/dFcK3XZbtCMxxpg8s0SQV2lp8NFH0KULVK8e7WiMMSbPLBHk1ZQp7tES/fpFOxJjjDkrlgjyavhwqFIFunaNdiTGGHNWLBHkxf79MHasaxsoYa9mMMYUbZYI8uKTT+DkSasWMsbEBEsEeTF8OFx2mT1kzhgTEywR5Nb27TB/Ptx6K4g9g88YU/RZIsgt/7sHrr46unEYY0w+sUSQW/buAWNMjLFEkFv+dw/Yu4mNMTEioolARDqLyBoRWS8ij4cY/pKILPH+1orIgUjGc9Z27nTvHmjfPtqRGGNMvonYK7VEJBF4HbgG2AosEJFxqrrKP46qDg4Y//dAs0jFky/s3QPGmBgUyRJBS2C9qm5U1VPAaKBHNuP3BUZFMJ6zN3MmlCtn7x4wxsSUSCaCmsCWgO6tXr8ziMiFQF1gegTjOXv2bmJjTAwqLI3FfYDPVTUt1EARuV9EUkQkZc+ePQUcmmf3bli1yqqFjDExJ5KJYBtQO6C7ltcvlD5kUy3kvR4zWVWTq1Wrlo8h5oK/fcAaio0xMSaSiWABUF9E6opICdzBflzwSCLSCKgEzI1gLGfP/27iFi2iHYkxxuSriCUCVU0FfgdMBn4EPlXVlSLyjIh0Dxi1DzBaVTVSseSLmTOhdWt7N7ExJuZEtNVTVScCE4P6PRXUPSSSMeSLbdtgxQro0yfakRhjTL4rLI3Fhdtbb7kHzPXtG+1IjDEm31kiyMmJE/D223DDDXDRRdGOxhhj8p0lgpx8+ins2QO//320IzHGmIiwRJAdVXj1VbjkEujUKdrRGGNMRNgtstmZNw8WLoQ33rCX0BhjYpaVCLLz2mtQsSLccUe0IzHGmIixRJCV3bvhs8/gnnvcg+aMMSZGWSLIypQpkJoKt98e7UiMMSaiLBFkZdo0qFTJXklpjIl5lghCUXWJoEMHSLBNZIyJbXaUC2XjRvj5Z+jYMdqRGGNMxFkiCGW6934cu3fAGBMHLBGEMm0a1KgBDRtGOxJjjIk4SwTBVF2JoFMnu4nMGBMXLBEEW7nSPVvI2geMMXHCEkGwadPcpyUCY0ycsEQQbPp0qFcPLrww2pEYY0yBsEQQKDXVvZLSSgPGmDhiicBvzRr3cLlDh+yyUWNMXLHHUB87Bg88AB9/DKVKwWOPQa9e0Y7KGGMKjCWCjz+G//4XBg+Gxx+H6tWjHZExxhQoSwRz5kDVqvB//2f3DRhj4pK1EXz/PbRubUnAGBO34rtEsHcvrF3rXj5jTBFz+vRptm7dyokTJ6IdiilESpUqRa1atShevHjY08R3Ipg71322bh3dOIzJg61bt1K+fHnq1KmDWInWAKrKvn372Lp1K3Xr1g17uviuGpozB4oXh+TkaEdiTK6dOHGCKlWqWBIw6USEKlWq5LqUGN+J4PvvoXlzKF062pEYkyeWBEywvPwm4jcRnDoFCxZYtZAxJu7FbyJYsgROnLBEYEwe7du3j6ZNm9K0aVPOO+88atasmd596tSpbKdNSUnhoYceynEZrfP5/3PQoEHUrFkTn8+Xr/Mt6uK3sXjOHPdpicCYPKlSpQpLliwBYMiQIZQrV44//vGP6cNTU1MpViz0ISY5OZnkMNrm5vj/T/OBz+djzJgx1K5dm1mzZtGhQ4d8m3eg7Na7sCpa0eanOXOgTh04//xoR2LMWfvb+JWs2n4oX+d56fkVePqGxrmapl+/fpQqVYrFixfTpk0b+vTpw8MPP8yJEycoXbo0H3zwAQ0bNmTmzJkMHTqUCRMmMGTIEH7++Wc2btzIzz//zKBBg9JLC+XKlePIkSPMnDmTIUOGULVqVVasWEGLFi3473//i4gwceJEHnnkEcqWLUubNm3YuHEjEyZMOCO2mTNn0rhxY2655RZGjRqVngh27drFgAED2LhxIwBvvvkmrVu3ZsSIEQwdOhQR4bLLLuOjjz6iX79+dOvWjd/85jdnxPfXv/6VSpUqsXr1atauXcuNN97Ili1bOHHiBA8//DD3338/AJMmTeLJJ58kLS2NqlWrMmXKFBo2bMicOXOoVq0aPp+PBg0aMHfuXKpVq5bn/Zcb8ZkIVF1Dcfv20Y7EmJizdetW5syZQ2JiIocOHWL27NkUK1aMqVOn8uSTT/LFF1+cMc3q1auZMWMGhw8fpmHDhgwcOPCM6+AXL17MypUrOf/882nTpg3ff/89ycnJPPDAA3z77bfUrVuXvn37ZhnXqFGj6Nu3Lz169ODJJ5/k9OnTFC9enIceeoh27doxZswY0tLSOHLkCCtXruS5555jzpw5VK1alV9++SXH9V60aBErVqxIv2zz/fffp3Llyhw/fpzLL7+cXr164fP56N+/f3q8v/zyCwkJCdx+++2MHDmSQYMGMXXqVJKSkgosCUC8JoKff4bt261ayMSM3J65R1Lv3r1JTEwE4ODBg9x1112sW7cOEeH06dMhp+natSslS5akZMmSVK9enV27dlGrVq1M47Rs2TK9X9OmTdm8eTPlypXjoosuSj/49u3bl2HDhp0x/1OnTjFx4kT+/e9/U758ea644gomT55Mt27dmD59OiNGjAAgMTGRihUrMmLECHr37k3VqlUBqFy5co7r3bJly0zX7r/66quMGTMGgC1btrBu3Tr27NlD27Zt08fzz/eee+6hR48eDBo0iPfff5+77747x+Xlp/hMBHYjmTERU7Zs2fTvf/3rX+nQoQNjxoxh8+bNtM+iFF6yZMn074mJiaSmpuZpnKxMnjyZAwcO0KRJEwCOHTtG6dKl6datW9jzAChWrFh6Q7PP58vUKB643jNnzmTq1KnMnTuXMmXK0L59+2yv7a9duzbnnnsu06dP54cffmDkyJG5iutsxedVQ0uWuBvJfvWraEdiTEw7ePAgNWvWBGD48OH5Pv+GDRuyceNGNm/eDMAnn3wScrxRo0bx7rvvsnnzZjZv3symTZuYMmUKx44do1OnTrz55psApKWlcfDgQTp27Mhnn33Gvn37ANKrhurUqcPChQsBGDduXJYlnIMHD1KpUiXKlCnD6tWrmTdvHgCtWrXi22+/ZdOmTZnmC3Dfffdx++23ZypRFZT4TATLlsGll7pkYIyJmMcee4wnnniCZs2a5eoMPlylS5fmjTfeoHPnzrRo0YLy5ctTsWLFTOMcO3aMSZMm0bVr1/R+ZcuW5corr2T8+PG88sorzJgxgyZNmtCiRQtWrVpF48aN+fOf/0y7du1ISkrikUceAaB///7MmjWLpKQk5s6dm6kUEKhz586kpqZyySWX8Pjjj9OqVSsAqlWrxrBhw+jZsydJSUnccsst6dN0796dI0eOFHi1EICoaoEv9GwkJydrSkrK2c2kVi33OkqvXtCYoujHH3/kkksuiXYYUXfkyBHKlSuHqvLggw9Sv359Bg8eHO2wci0lJYXBgwcze/bss55XqN+GiCxU1ZDX7MZfiWDfPti2DS67LNqRGGPywTvvvEPTpk1p3LgxBw8e5IEHHoh2SLn2wgsv0KtXL/7xj39EZfnxVyKYORM6dIDJk+Haa/MtLmMKmpUITFYKVYlARDqLyBoRWS8ij2cxzs0iskpEVorIx5GMB4Dly92nd/WAMcbEu4hdPioiicDrwDXAVmCBiIxT1VUB49QHngDaqOp+EYn8C4OXLXOvpjzvvIgvyhhjioJIlghaAutVdaOqngJGAz2CxukPvK6q+wFUdXcE43GWLXPtA/b4XmOMASKbCGoCWwK6t3r9AjUAGojI9yIyT0Q6h5qRiNwvIikikrJnz568R5SWBitWWEOxMcYEiPZVQ8WA+kB7oC/wjoicEzySqg5T1WRVTT6r529s3AjHjlkiMCYfdOjQgcmTJ2fq9/LLLzNw4MAsp2nfvj3+iz26dOnCgQMHzhhnyJAhDB06NNtljx07llWr0muZeeqpp5g6dWpuws9WvD2uOpKJYBtQO6C7ltcv0FZgnKqeVtVNwFpcYoiMZcvcpyUCY85a3759GT16dKZ+o0ePzvbBb4EmTpzIOeeccd4XluBE8Mwzz3D11VfnaV7Bgh9XHSmRuMEuryKZCBYA9UWkroiUAPoA44LGGYsrDSAiVXFVRRsjFtHy5ZCQ4O4qNiaWDBrknqabn3+DBmW7yN/85jd89dVX6c/b2bx5M9u3b+eqq65i4MCBJCcn07hxY55++umQ09epU4e9e/cC8Pzzz9OgQQOuvPJK1qxZkz7OO++8w+WXX05SUhK9evXi2LFjzJkzh3HjxvHoo4/StGlTNmzYQL9+/fj8888BmDZtGs2aNaNJkybcc889nDx5Mn15Tz/9NM2bN6dJkyasXr06ZFz+x1UPHDiQUaNGpffftWsXN910E0lJSSQlJaW/K2HEiBFcdtllJCUlcccddwBkigfc46r9877qqqvo3r07l3rHoRtvvJEWLVrQuHHjTA/MmzRpEs2bNycpKYlOnTrh8/moX78+/upxn8/HxRdfzFlVl3silghUNRX4HTAZ+BH4VFVXisgzItLdG20ysE9EVgEzgEdVdV+kYmLZMqhf395RbEw+qFy5Mi1btuTrr78GXGng5ptvRkR4/vnnSUlJYdmyZcyaNYtl/tJ4CAsXLmT06NEsWbKEiRMnsmDBgvRhPXv2ZMGCBSxdupRLLrmE9957j9atW9O9e3defPFFlixZQr169dLHP3HiBP369eOTTz5h+fLlpKampj9HCKBq1aosWrSIgQMHZln95H9c9U033cRXX32V/jwh/+Oqly5dyqJFi2jcuHH646qnT5/O0qVLeeWVV3LcbosWLeKVV15h7dq1gHtc9cKFC0lJSeHVV19l37597Nmzh/79+/PFF1+wdOlSPvvss0yPqwby9XHVEX36qKpOBCYG9Xsq4LsCj3h/kbdsmXtZvTGx5uWXo7JYf/VQjx49GD16NO+99x4An376KcOGDSM1NZUdO3awatUqLsuiSnb27NncdNNNlClTBnDP3PFbsWIFf/nLXzhw4ABHjhzhuuuuyzaeNWvWULduXRo0aADAXXfdxeuvv84gr3TTs2dPAFq0aMGXX355xvTx+rjq+HkM9ZEjsGED9OsX7UiMiRk9evRg8ODBLFq0iGPHjtGiRQs2bdrE0KFDWbBgAZUqVaJfv37ZPoI5O/369WPs2LEkJSUxfPhwZs6ceVbx+h9lndVjrOP1cdXRvmqo4KxY4T6todiYfFOuXDk6dOjAPffck95IfOjQIcqWLUvFihXZtWtXetVRVtq2bcvYsWM5fvw4hw8fZvz48enDDh8+TI0aNTh9+nSmg1758uU5fPjwGfNq2LAhmzdvZv369QB89NFHtGvXLuz1idfHVcdPIrArhoyJiL59+7J06dL0RJCUlESzZs1o1KgRt956K23atMl2+ubNm3PLLbeQlJTE9ddfz+WXX54+7Nlnn+WKK66gTZs2NGrUKL1/nz59ePHFF2nWrBkbNmxI71+qVCk++OADevfuTZMmTUhISGDAgAFhrUc8P646fh4697//wfDh8OWXdlexiQn20Ln4FM7jqnP70Ln4aSPo0cP9GWNMEfXCCy/w5ptv5vurLOOnasgYY4q4xx9/nJ9++okrr7wyX+dricCYIqyoVe2ayMvLb8ISgTFFVKlSpdi3b58lA5NOVdm3bx+lSpXK1XTx00ZgTIypVasWW7duzZdHDJjYUapUKWrVqpWraSwRGFNEFS9ePNMdqsbklVUNGWNMnLNEYIwxcc4SgTHGxLkid2exiOwBfsrFJFWBvREKpzCLx/WOx3WG+FzveFxnOLv1vlBVQz6zusglgtwSkZSsbquOZfG43vG4zhCf6x2P6wyRW2+rGjLGmDhnicAYY+JcPCSCYTmPEpPicb3jcZ0hPtc7HtcZIrTeMd9GYIwxJnvxUCIwxhiTDUsExhgT52I6EYhIZxFZIyLrReTxaMcTCSJSW0RmiMgqEVkpIg97/SuLyBQRWed9Vop2rPlNRBJFZLGITPC664rIfG9/fyIiJaIdY34TkXNE5HMRWS0iP4rIr+NkXw/2ft8rRGSUiJSKtf0tIu+LyG4RWRHQL+S+FedVb92XiUjzs1l2zCYCEUkEXgeuBy4F+orIpdGNKiJSgT+o6qVAK+BBbz0fB6apan1gmtcdax4Gfgzo/ifwkqpeDOwH7o1KVJH1CjBJVRsBSbj1j+l9LSI1gYeAZFX9FZAI9CH29vdwoHNQv6z27fVAfe/vfuDNs1lwzCYCoCWwXlU3quopYDQQc++qVNUdqrrI+34Yd2CoiVvXD73RPgRujE6EkSEitYCuwLtetwAdgc+9UWJxnSsCbYH3AFT1lKoeIMb3tacYUFpEigFlgB3E2P5W1W+BX4J6Z7VvewAj1JkHnCMiNfK67FhOBDWBLQHdW71+MUtE6gDNgPnAuaq6wxu0Ezg3SmFFysvAY4DP664CHFDVVK87Fvd3XWAP8IFXJfauiJQlxve1qm4DhgI/4xLAQWAhsb+/Iet9m6/Ht1hOBHFFRMoBXwCDVPVQ4DB11wjHzHXCItIN2K2qC6MdSwErBjQH3lTVZsBRgqqBYm1fA3j14j1wifB8oCxnVqHEvEju21hOBNuA2gHdtbx+MUdEiuOSwEhV/dLrvctfVPQ+d0crvghoA3QXkc24Kr+OuLrzc7yqA4jN/b0V2Kqq873uz3GJIZb3NcDVwCZV3aOqp4Evcb+BWN/fkPW+zdfjWywnggVAfe/KghK4xqVxUY4p33l14+8BP6rqvwMGjQPu8r7fBfyvoGOLFFV9QlVrqWod3H6drqq3ATOA33ijxdQ6A6jqTmCLiDT0enUCVhHD+9rzM9BKRMp4v3f/esf0/vZktW/HAXd6Vw+1Ag4GVCHlnqrG7B/QBVgLbAD+HO14IrSOV+KKi8uAJd5fF1yd+TRgHTAVqBztWCO0/u2BCd73i4AfgPXAZ0DJaMcXgfVtCqR4+3ssUCke9jXwN2A1sAL4CCgZa/sbGIVrAzmNK/3dm9W+BQR3VeQGYDnuiqo8L9seMWGMMXEulquGjDHGhMESgTHGxDlLBMYYE+csERhjTJyzRGCMMXHOEoGJayKSJiJLAv7y7YFtIlIn8EmSxhRWxXIexZiYdlxVm0Y7CGOiyUoExoQgIptF5F8islxEfhCRi73+dURkuvcM+GkicoHX/1wRGSMiS72/1t6sEkXkHe9Z+t+ISGlv/HoiMklEForIbBFp5PXv7T1zf6mIfBuVlTdxxxKBiXelg6qGbgkYdlBVmwD/wT3tFOA14ENVvQwYCbzq9X8VmKWqSbjn/6z0+tcHXlfVxsABoJfXfxjwe1VtAfwReMPr/xRwnTef7vm9ssaEYncWm7gmIkdUtVyI/puBjqq60Xuo305VrSIie4Eaqnra679DVauKyB6glqqeDJhHHWCKupeKICJ/AorjksoeYE3AIkuq6iUi8hZQD/gU+FJV90VgtY3JxNoIjMmaZvE9N04GfE8DSuNK4gdCtU2o6gARuQL30p2FItLCkoGJNKsaMiZrtwR8zvW+z8E98RTgNmC2930aMBDS36VcMauZqntfxCYR6e2NLyKS5H2vp6rzVfUpXKmhdlbzMSa/WCIw8S64jeCFgGGVRGQZ7t3Ig71+vwfu9vrf4Q3D++wgIstxb8/K6f3YtwH3ishSXHuC/zWqL3oN1CtwSWfp2a6gMTmxNgJjQvDaCJJVdW+0YzEm0qxEYIwxcc5KBMYYE+esRGCMMXHOEoExxsQ5SwTGGBPnLBEYY0ycs0RgjDFx7v8BOzuh2m+8JIoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbDWslucGxaa"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTtNMihlGqTg",
        "outputId": "41322a70-92d4-4fdf-d71a-da64021f662a"
      },
      "source": [
        "prediction_test_data = test_data\n",
        "predictions = network.predict(prediction_test_data)\n",
        "hit = np.argmax(predictions) == np.array(test_labels)\n",
        "print(f\"{len(hit)} out of {len(predictions)} \")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85443 out of 85443 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTmyXbrIG9tZ",
        "outputId": "bf527eb5-d47e-4aa0-f904-58f2252c206f"
      },
      "source": [
        "#Accuracy on activation ='tanh' \n",
        "print(f'Accuracy: {test_acc*100}%')"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.85723638534546%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1q4epn0CdDp"
      },
      "source": [
        "# By Using activation function 'relu' with dropout of 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFQ3bujkpfrZ",
        "outputId": "09d420be-da4b-4e43-d232-d6ddf634c172"
      },
      "source": [
        "network1 = models.Sequential()\n",
        "network1.add(layers.Dense(30,activation=\"relu\",input_shape=(len(train_data.columns),) ))\n",
        "network1.add(layers.Dropout(0.5))\n",
        "network1.add(layers.Dense(20,activation=\"relu\"))\n",
        "network1.add(layers.Dropout(0.5))\n",
        "network1.add(layers.Dense(10,activation=\"relu\"))\n",
        "network1.add(layers.Dropout(0.5))\n",
        "network1.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "network1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "with tf.device('/device:GPU:1'):\n",
        "  MODEL1 = network1.fit(train_data,train_labels,epochs=100,batch_size=512,validation_data=(val_data,val_labels))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "279/279 [==============================] - 2s 4ms/step - loss: 0.2902 - acc: 0.9122 - val_loss: 0.0148 - val_acc: 0.9980\n",
            "Epoch 2/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0320 - acc: 0.9982 - val_loss: 0.0122 - val_acc: 0.9980\n",
            "Epoch 3/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0224 - acc: 0.9979 - val_loss: 0.0109 - val_acc: 0.9980\n",
            "Epoch 4/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0172 - acc: 0.9981 - val_loss: 0.0102 - val_acc: 0.9980\n",
            "Epoch 5/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0152 - acc: 0.9980 - val_loss: 0.0101 - val_acc: 0.9980\n",
            "Epoch 6/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0125 - acc: 0.9981 - val_loss: 0.0097 - val_acc: 0.9980\n",
            "Epoch 7/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0138 - acc: 0.9984 - val_loss: 0.0086 - val_acc: 0.9980\n",
            "Epoch 8/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0126 - acc: 0.9982 - val_loss: 0.0084 - val_acc: 0.9980\n",
            "Epoch 9/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0079 - val_acc: 0.9984\n",
            "Epoch 10/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0106 - acc: 0.9983 - val_loss: 0.0074 - val_acc: 0.9985\n",
            "Epoch 11/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0072 - val_acc: 0.9988\n",
            "Epoch 12/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.0073 - val_acc: 0.9989\n",
            "Epoch 13/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0094 - acc: 0.9985 - val_loss: 0.0067 - val_acc: 0.9990\n",
            "Epoch 14/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0065 - val_acc: 0.9991\n",
            "Epoch 15/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0101 - acc: 0.9983 - val_loss: 0.0063 - val_acc: 0.9991\n",
            "Epoch 16/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0065 - val_acc: 0.9991\n",
            "Epoch 17/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0065 - val_acc: 0.9991\n",
            "Epoch 18/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0066 - val_acc: 0.9991\n",
            "Epoch 19/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0064 - val_acc: 0.9991\n",
            "Epoch 20/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0079 - acc: 0.9985 - val_loss: 0.0068 - val_acc: 0.9991\n",
            "Epoch 21/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9990\n",
            "Epoch 22/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0063 - val_acc: 0.9991\n",
            "Epoch 23/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9990\n",
            "Epoch 24/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0067 - val_acc: 0.9990\n",
            "Epoch 25/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0070 - acc: 0.9987 - val_loss: 0.0063 - val_acc: 0.9988\n",
            "Epoch 26/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0060 - acc: 0.9989 - val_loss: 0.0062 - val_acc: 0.9989\n",
            "Epoch 27/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.0063 - val_acc: 0.9989\n",
            "Epoch 28/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0063 - val_acc: 0.9988\n",
            "Epoch 29/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9988\n",
            "Epoch 30/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.0070 - val_acc: 0.9987\n",
            "Epoch 31/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0066 - val_acc: 0.9988\n",
            "Epoch 32/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0066 - val_acc: 0.9986\n",
            "Epoch 33/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0076 - acc: 0.9986 - val_loss: 0.0066 - val_acc: 0.9986\n",
            "Epoch 34/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0068 - val_acc: 0.9987\n",
            "Epoch 35/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0065 - val_acc: 0.9987\n",
            "Epoch 36/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.0069 - val_acc: 0.9987\n",
            "Epoch 37/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9987\n",
            "Epoch 38/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9986 - val_loss: 0.0070 - val_acc: 0.9987\n",
            "Epoch 39/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0067 - acc: 0.9988 - val_loss: 0.0065 - val_acc: 0.9986\n",
            "Epoch 40/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0059 - acc: 0.9989 - val_loss: 0.0066 - val_acc: 0.9987\n",
            "Epoch 41/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0066 - val_acc: 0.9986\n",
            "Epoch 42/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0065 - val_acc: 0.9987\n",
            "Epoch 43/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.0066 - val_acc: 0.9987\n",
            "Epoch 44/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.0067 - val_acc: 0.9986\n",
            "Epoch 45/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0065 - val_acc: 0.9988\n",
            "Epoch 46/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0071 - val_acc: 0.9988\n",
            "Epoch 47/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0079 - val_acc: 0.9988\n",
            "Epoch 48/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9990\n",
            "Epoch 49/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0060 - val_acc: 0.9990\n",
            "Epoch 50/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0068 - val_acc: 0.9989\n",
            "Epoch 51/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0061 - val_acc: 0.9989\n",
            "Epoch 52/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0062 - val_acc: 0.9989\n",
            "Epoch 53/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0067 - val_acc: 0.9989\n",
            "Epoch 54/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0092 - val_acc: 0.9989\n",
            "Epoch 55/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0067 - val_acc: 0.9989\n",
            "Epoch 56/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0075 - val_acc: 0.9989\n",
            "Epoch 57/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0070 - val_acc: 0.9989\n",
            "Epoch 58/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0074 - val_acc: 0.9990\n",
            "Epoch 59/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0070 - acc: 0.9987 - val_loss: 0.0068 - val_acc: 0.9989\n",
            "Epoch 60/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0082 - val_acc: 0.9989\n",
            "Epoch 61/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0066 - val_acc: 0.9989\n",
            "Epoch 62/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0073 - val_acc: 0.9990\n",
            "Epoch 63/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.0066 - val_acc: 0.9990\n",
            "Epoch 64/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0072 - acc: 0.9985 - val_loss: 0.0067 - val_acc: 0.9989\n",
            "Epoch 65/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0078 - val_acc: 0.9990\n",
            "Epoch 66/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0076 - val_acc: 0.9991\n",
            "Epoch 67/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0070 - val_acc: 0.9990\n",
            "Epoch 68/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0075 - val_acc: 0.9990\n",
            "Epoch 69/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0073 - val_acc: 0.9990\n",
            "Epoch 70/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0075 - val_acc: 0.9989\n",
            "Epoch 71/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0075 - val_acc: 0.9990\n",
            "Epoch 72/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0068 - val_acc: 0.9991\n",
            "Epoch 73/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0080 - val_acc: 0.9990\n",
            "Epoch 74/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0236 - val_acc: 0.9990\n",
            "Epoch 75/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0347 - acc: 0.9931 - val_loss: 0.0073 - val_acc: 0.9990\n",
            "Epoch 76/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0073 - val_acc: 0.9990\n",
            "Epoch 77/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0086 - val_acc: 0.9990\n",
            "Epoch 78/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0079 - val_acc: 0.9989\n",
            "Epoch 79/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0076 - val_acc: 0.9990\n",
            "Epoch 80/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9991\n",
            "Epoch 81/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0076 - val_acc: 0.9991\n",
            "Epoch 82/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0072 - acc: 0.9985 - val_loss: 0.0082 - val_acc: 0.9991\n",
            "Epoch 83/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0078 - val_acc: 0.9990\n",
            "Epoch 84/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0069 - val_acc: 0.9990\n",
            "Epoch 85/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0065 - acc: 0.9986 - val_loss: 0.0082 - val_acc: 0.9989\n",
            "Epoch 86/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0097 - val_acc: 0.9990\n",
            "Epoch 87/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0084 - val_acc: 0.9990\n",
            "Epoch 88/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0063 - val_acc: 0.9990\n",
            "Epoch 89/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0078 - val_acc: 0.9990\n",
            "Epoch 90/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0085 - val_acc: 0.9990\n",
            "Epoch 91/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0093 - val_acc: 0.9990\n",
            "Epoch 92/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9991\n",
            "Epoch 93/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0112 - val_acc: 0.9991\n",
            "Epoch 94/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0090 - val_acc: 0.9990\n",
            "Epoch 95/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.0106 - val_acc: 0.9990\n",
            "Epoch 96/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0108 - val_acc: 0.9990\n",
            "Epoch 97/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0098 - val_acc: 0.9990\n",
            "Epoch 98/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0100 - val_acc: 0.9990\n",
            "Epoch 99/100\n",
            "279/279 [==============================] - 1s 3ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9990\n",
            "Epoch 100/100\n",
            "279/279 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 0.9987 - val_loss: 0.0108 - val_acc: 0.9990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ldj0_c5ac2do",
        "outputId": "a3a12f4d-1642-4e8b-a11f-1844fbe84b3a"
      },
      "source": [
        "history_dict = MODEL1.history\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "epoches = np.arange(1,len(history_dict['acc'])+1)\n",
        "plt.plot(epoches,acc_values,'-',label=\"Training Accuracy\")\n",
        "plt.plot(epoches,val_acc_values,'r',label=\"Validation Accuracy\")\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf145CfFDS-n"
      },
      "source": [
        "# Evaluation of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GNJnwmXc2do",
        "outputId": "8f2a7a6e-9328-4f94-fbed-9c46fe9d2c38"
      },
      "source": [
        "test_loss , test_acc = network1.evaluate(test_data,test_labels)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2671/2671 [==============================] - 4s 2ms/step - loss: 0.0052 - acc: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRY9FmSSDcMY"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8eJ1kkcc2dp",
        "outputId": "3b5f2844-0d0b-4acb-f3db-bd7e499e117c"
      },
      "source": [
        "prediction_test_data = test_data\n",
        "predictions = network1.predict(prediction_test_data)\n",
        "hit = np.argmax(predictions) == np.array(test_labels)\n",
        "print(f\"{len(hit)} out of {len(predictions)} \")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85443 out of 85443 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLcn-aSkp1E2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0c363bc-787c-44e1-9d87-e17232ebe403"
      },
      "source": [
        "#accuracy of the network while activation = 'relu' with dropout of 0.5\n",
        "display(f'Test Accuracy: {test_acc*100}%')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test Accuracy: 99.95201230049133%'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJslB7QHLXrw"
      },
      "source": [
        "Perfomance is better on activation = relu with dropout of 0.5 as compare to the activation= tanh while epochs = 100 for both networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUkAM9HPc2dp"
      },
      "source": [
        ""
      ],
      "execution_count": 155,
      "outputs": []
    }
  ]
}